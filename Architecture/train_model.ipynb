{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of channels: 1\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "\n",
    "image = Image.open(\"/media/user/9c7eaef1-35fa-4210-889c-9e2b99342586/user/abul/RESM NEW NEW/RESM/20100903_0025_hr_patch_11.jpg\")\n",
    "mode = image.mode\n",
    "channels = {\"L\": 1, \"RGB\": 3, \"RGBA\": 4, \"CMYK\": 4}  # Mapping for common modes\n",
    "num_channels = channels.get(mode, \"Unknown\")\n",
    "print(f\"Number of channels: {num_channels}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchsummary import summary\n",
    "import torch.optim as optim\n",
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, random_split\n",
    "import random\n",
    "import datetime\n",
    "\n",
    "\n",
    "from loop import train_loop\n",
    "from dcnet import DCNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SuperResolutionDataset(Dataset):\n",
    "    def __init__(self, lr_dir, hr_dir, lr_transform=None, hr_transform=None):\n",
    "        self.lr_dir = lr_dir\n",
    "        self.hr_dir = hr_dir\n",
    "        self.lr_images = os.listdir(lr_dir)\n",
    "        self.lr_transform = lr_transform\n",
    "        self.hr_transform = hr_transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.lr_images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        lr_image_path = os.path.join(self.lr_dir, self.lr_images[idx])\n",
    "        hr_image_path = os.path.join(self.hr_dir, self.lr_images[idx])\n",
    "\n",
    "        lr_image = Image.open(lr_image_path).convert(\"L\").resize((64, 64))  # Resize to 64x64\n",
    "        hr_image = Image.open(hr_image_path).convert(\"L\").resize((256, 256))  # Resize to 256x256\n",
    "\n",
    "        if self.lr_transform:\n",
    "            lr_image = self.lr_transform(lr_image)\n",
    "        if self.hr_transform:\n",
    "            hr_image = self.hr_transform(hr_image)\n",
    "\n",
    "        return {'image': lr_image, 'label': hr_image}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataloaders(train_dataset, val_dataset, batch_size=8): # setting the batch size to 2\n",
    "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "    return train_loader, val_loader\n",
    "\n",
    "\n",
    "def setup_training(model, device, train_loader, val_loader, epochs=100, patience=10):\n",
    "    # Ensure the model is moved to the correct device\n",
    "    model = model.to(device)\n",
    "\n",
    "    # Initialize optimizer\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=2e-4, betas=(0.9, 0.999))\n",
    "\n",
    "    # Initialize learning rate scheduler\n",
    "    scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[25, 45, 65, 85], gamma=0.5)\n",
    "\n",
    "    # Initialize loss function\n",
    "    criterion = nn.L1Loss()\n",
    "\n",
    "    # Prepare output directory\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    output_dir = os.path.join(\"models\", timestamp)\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # Start training loop\n",
    "    train_loop(\n",
    "        model=model,\n",
    "        train_loader=train_loader,\n",
    "        val_loader=val_loader,\n",
    "        device=device,\n",
    "        num_epochs=epochs\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CPU instead of GPU.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Check if GPU is available\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"GPU is being used. Device:\", torch.cuda.get_device_name(0))\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"Using CPU instead of GPU.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchinfo import summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is not available.\n",
      "==========================================================================================================================================================================\n",
      "Layer (type:depth-idx)                                                 Input Shape               Output Shape              Param #                   Trainable\n",
      "==========================================================================================================================================================================\n",
      "DCNet                                                                  [1, 1, 64, 64]            [1, 1, 256, 256]          --                        True\n",
      "├─ShallowFeatureExtractor: 1-1                                         [1, 1, 64, 64]            [1, 180, 64, 64]          --                        True\n",
      "│    └─Conv2d: 2-1                                                     [1, 1, 64, 64]            [1, 180, 64, 64]          1,620                     True\n",
      "│    └─Sequential: 2-2                                                 [1, 180, 64, 64]          [1, 180, 64, 64]          --                        True\n",
      "│    │    └─ResidualBlock: 3-1                                         [1, 180, 64, 64]          [1, 180, 64, 64]          --                        True\n",
      "│    │    │    └─Conv2d: 4-1                                           [1, 180, 64, 64]          [1, 180, 64, 64]          291,600                   True\n",
      "│    │    │    └─ReLU: 4-2                                             [1, 180, 64, 64]          [1, 180, 64, 64]          --                        --\n",
      "│    │    │    └─Conv2d: 4-3                                           [1, 180, 64, 64]          [1, 180, 64, 64]          291,600                   True\n",
      "│    │    └─ResidualBlock: 3-2                                         [1, 180, 64, 64]          [1, 180, 64, 64]          --                        True\n",
      "│    │    │    └─Conv2d: 4-4                                           [1, 180, 64, 64]          [1, 180, 64, 64]          291,600                   True\n",
      "│    │    │    └─ReLU: 4-5                                             [1, 180, 64, 64]          [1, 180, 64, 64]          --                        --\n",
      "│    │    │    └─Conv2d: 4-6                                           [1, 180, 64, 64]          [1, 180, 64, 64]          291,600                   True\n",
      "├─ModuleList: 1-2                                                      --                        --                        --                        True\n",
      "│    └─ResidualGroup: 2-3                                              [1, 180, 64, 64]          [1, 180, 64, 64]          --                        True\n",
      "│    │    └─ModuleList: 3-3                                            --                        --                        --                        True\n",
      "│    │    │    └─DCB: 4-7                                              [1, 180, 64, 64]          [1, 180, 64, 64]          1,531,440                 True\n",
      "│    │    │    └─DCB: 4-8                                              [1, 180, 64, 64]          [1, 180, 64, 64]          1,531,440                 True\n",
      "│    │    └─Conv2d: 3-4                                                [1, 180, 64, 64]          [1, 180, 64, 64]          291,600                   True\n",
      "│    └─ResidualGroup: 2-4                                              [1, 180, 64, 64]          [1, 180, 64, 64]          --                        True\n",
      "│    │    └─ModuleList: 3-5                                            --                        --                        --                        True\n",
      "│    │    │    └─DCB: 4-9                                              [1, 180, 64, 64]          [1, 180, 64, 64]          1,531,440                 True\n",
      "│    │    │    └─DCB: 4-10                                             [1, 180, 64, 64]          [1, 180, 64, 64]          1,531,440                 True\n",
      "│    │    └─Conv2d: 3-6                                                [1, 180, 64, 64]          [1, 180, 64, 64]          291,600                   True\n",
      "│    └─ResidualGroup: 2-5                                              [1, 180, 64, 64]          [1, 180, 64, 64]          --                        True\n",
      "│    │    └─ModuleList: 3-7                                            --                        --                        --                        True\n",
      "│    │    │    └─DCB: 4-11                                             [1, 180, 64, 64]          [1, 180, 64, 64]          1,531,440                 True\n",
      "│    │    │    └─DCB: 4-12                                             [1, 180, 64, 64]          [1, 180, 64, 64]          1,531,440                 True\n",
      "│    │    └─Conv2d: 3-8                                                [1, 180, 64, 64]          [1, 180, 64, 64]          291,600                   True\n",
      "│    └─ResidualGroup: 2-6                                              [1, 180, 64, 64]          [1, 180, 64, 64]          --                        True\n",
      "│    │    └─ModuleList: 3-9                                            --                        --                        --                        True\n",
      "│    │    │    └─DCB: 4-13                                             [1, 180, 64, 64]          [1, 180, 64, 64]          1,531,440                 True\n",
      "│    │    │    └─DCB: 4-14                                             [1, 180, 64, 64]          [1, 180, 64, 64]          1,531,440                 True\n",
      "│    │    └─Conv2d: 3-10                                               [1, 180, 64, 64]          [1, 180, 64, 64]          291,600                   True\n",
      "│    └─ResidualGroup: 2-7                                              [1, 180, 64, 64]          [1, 180, 64, 64]          --                        True\n",
      "│    │    └─ModuleList: 3-11                                           --                        --                        --                        True\n",
      "│    │    │    └─DCB: 4-15                                             [1, 180, 64, 64]          [1, 180, 64, 64]          1,531,440                 True\n",
      "│    │    │    └─DCB: 4-16                                             [1, 180, 64, 64]          [1, 180, 64, 64]          1,531,440                 True\n",
      "│    │    └─Conv2d: 3-12                                               [1, 180, 64, 64]          [1, 180, 64, 64]          291,600                   True\n",
      "├─Conv2d: 1-3                                                          [1, 180, 64, 64]          [1, 180, 64, 64]          291,600                   True\n",
      "├─ProgressiveReconstruction: 1-4                                       [1, 180, 64, 64]          [1, 1, 256, 256]          --                        True\n",
      "│    └─ModuleList: 2-8                                                 --                        --                        --                        True\n",
      "│    │    └─UpsampleBlock: 3-13                                        [1, 180, 64, 64]          [1, 180, 256, 256]        --                        True\n",
      "│    │    │    └─Conv2d: 4-17                                          [1, 180, 64, 64]          [1, 2880, 64, 64]         518,400                   True\n",
      "│    │    │    └─PixelShuffle: 4-18                                    [1, 2880, 64, 64]         [1, 180, 256, 256]        --                        --\n",
      "│    │    │    └─ReLU: 4-19                                            [1, 180, 256, 256]        [1, 180, 256, 256]        --                        --\n",
      "│    └─Conv2d: 2-9                                                     [1, 180, 256, 256]        [1, 1, 256, 256]          1,620                     True\n",
      "==========================================================================================================================================================================\n",
      "Total params: 18,752,040\n",
      "Trainable params: 18,752,040\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (G): 73.90\n",
      "==========================================================================================================================================================================\n",
      "Input size (MB): 0.02\n",
      "Forward/backward pass size (MB): 1457.41\n",
      "Params size (MB): 69.82\n",
      "Estimated Total Size (MB): 1527.25\n",
      "==========================================================================================================================================================================\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    if torch.cuda.is_available():\n",
    "        print(\"CUDA is available!\")\n",
    "        print(f\"Number of available GPUs: {torch.cuda.device_count()}\")\n",
    "        print(f\"Current device: {torch.cuda.current_device()}\")\n",
    "        print(f\"Device name: {torch.cuda.get_device_name(torch.cuda.current_device())}\")\n",
    "    else:\n",
    "        print(\"CUDA is not available.\")\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    model = DCNet(\n",
    "        in_channels=1,\n",
    "        channels=180,\n",
    "        rg_depths=[2,2,2,2,2],   # 5 RGs × 2 DCBs = 10 blocks\n",
    "        num_heads=[6,6,6,6,6],\n",
    "        mlp_ratio=2.0,\n",
    "        window_size=(4,4),\n",
    "        scale_factors=[4],\n",
    "        out_channels=1\n",
    "    )\n",
    "\n",
    "    transform_lr = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0,), (1.0,))\n",
    "    ])\n",
    "\n",
    "    transform_hr = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "\n",
    "    ])\n",
    "\n",
    "    # # Load the dataset\n",
    "    # lr_dir = \"/media/user/9c7eaef1-35fa-4210-889c-9e2b99342586/user/abul/RESM/sdo patches/dataset sdo patches low res\"\n",
    "    # hr_dir = \"/media/user/9c7eaef1-35fa-4210-889c-9e2b99342586/user/abul/RESM/sdo patches/dataset sdo patches\"\n",
    "\n",
    "    # full_dataset = SuperResolutionDataset(\n",
    "    #     lr_dir=lr_dir,\n",
    "    #     hr_dir=hr_dir,\n",
    "    #     lr_transform=transform_lr,\n",
    "    #     hr_transform=transform_hr\n",
    "    # )\n",
    "\n",
    "\n",
    "    # # Splitting the dataset\n",
    "    # train_size = int(0.8 * len(full_dataset))\n",
    "    # val_size = len(full_dataset) - train_size\n",
    "\n",
    "    # train_dataset, val_dataset = random_split(full_dataset, [train_size, val_size])\n",
    "    # train_loader, val_loader = dataloaders(train_dataset, val_dataset, batch_size=32)\n",
    "\n",
    "    print(summary(\n",
    "    model, \n",
    "    input_size=(1, 1, 64, 64),  # Batch size = 1, Channels = 1, Height = 64, Width = 64\n",
    "    device=device, \n",
    "    col_names=[\"input_size\", \"output_size\", \"num_params\", \"trainable\"], \n",
    "    depth=4\n",
    "    ))\n",
    "    # setup_training(model, device, train_loader, val_loader)\n",
    "\n",
    "main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MESR(in_channels=1, mid_channels=32, out_channels=1, num_blocks=12).to(device)\n",
    "model.load_state_dict(torch.load(\"model_output/Mar07_2137/model_weight_epoch30.pth\"))\n",
    "# model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from predict import prediction\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    # transforms.Normalize(mean=[0.5], std=[0.5])\n",
    "    transforms.Lambda(lambda x: x * 255.0),\n",
    "])\n",
    "\n",
    "def prediction(model, image_path):\n",
    "    model.eval()\n",
    "    image = Image.open(image_path).convert('L')\n",
    "    image = transform(image).unsqueeze(0).to(device)\n",
    "    with torch.inference_mode():\n",
    "        output = model(image)\n",
    "    return output.squeeze(0).cpu()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "import cv2\n",
    "\n",
    "# Example usage with visualization\n",
    "low_res_image_path = '/media/user/9c7eaef1-35fa-4210-889c-9e2b99342586/user/abul/RESM NEW NEW/RESM/20100903_0025_hr_patch_11.jpg'  # Replace with your low-res image path\n",
    "hr_image_path = '/media/user/9c7eaef1-35fa-4210-889c-9e2b99342586/user/abul/RESM/sdo patches/dataset sdo patches/20100903_0025_hr_patch_11.jpg'  # Replace with your high-res image path\n",
    "\n",
    "# Get SRCNN/MESR enhanced image\n",
    "predicted_image_tensor = prediction(model, low_res_image_path)\n",
    "predicted_image_pil = transforms.ToPILImage()(predicted_image_tensor)  # Convert tensor to PIL image\n",
    "predicted_image_np = np.array(predicted_image_pil)  # Convert PIL to NumPy array\n",
    "\n",
    "# Load low-resolution image\n",
    "low_res_pil = Image.open(low_res_image_path).convert('L')\n",
    "low_res_np = np.array(low_res_pil)\n",
    "\n",
    "# Load ground truth high-resolution image\n",
    "hr_pil = Image.open(hr_image_path).convert('L')\n",
    "hr_np = np.array(hr_pil)\n",
    "\n",
    "# Perform bicubic interpolation\n",
    "bicubic_np = cv2.resize(low_res_np, (predicted_image_np.shape[1], predicted_image_np.shape[0]), interpolation=cv2.INTER_CUBIC)\n",
    "\n",
    "# Visualization using matplotlib\n",
    "plt.figure(figsize=(24, 6))  # Adjust figure size as needed\n",
    "\n",
    "# Subplot 1: Low-Resolution Image\n",
    "plt.subplot(1, 4, 1)\n",
    "plt.imshow(low_res_np, cmap='gray')\n",
    "plt.title('Low-Resolution')\n",
    "plt.axis('off')\n",
    "\n",
    "# Subplot 2: Bicubic Interpolation Image\n",
    "plt.subplot(1, 4, 2)\n",
    "plt.imshow(bicubic_np, cmap='gray')\n",
    "plt.title('Bicubic Interpolation')\n",
    "plt.axis('off')\n",
    "\n",
    "# Subplot 3: MESR Enhanced Image\n",
    "plt.subplot(1, 4, 3)\n",
    "plt.imshow(predicted_image_np, cmap='gray')\n",
    "plt.title('MESR Enhanced')\n",
    "plt.axis('off')\n",
    "\n",
    "# Subplot 4: Ground Truth (High-Resolution) Image\n",
    "plt.subplot(1, 4, 4)\n",
    "plt.imshow(hr_np, cmap='gray')\n",
    "plt.title('Ground Truth')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Optionally save the images\n",
    "predicted_image_pil.save('path_to_save_predicted_image.png')\n",
    "bicubic_pil = Image.fromarray(bicubic_np)\n",
    "bicubic_pil.save('path_to_save_bicubic_image.png')\n",
    "hr_pil.save('path_to_save_hr_image.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_image_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
